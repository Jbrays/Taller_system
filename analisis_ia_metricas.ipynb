{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4587e4cb",
   "metadata": {},
   "source": [
    "# 📊 Análisis de IA y Métricas - Sistema de Emparejamiento Docente-Curso\n",
    "\n",
    "**Proyecto:** Sistema de Recomendación Inteligente  \n",
    "**Fecha:** Octubre 2025  \n",
    "**Modelo:** SBERT `paraphrase-multilingual-MiniLM-L12-v2`\n",
    "\n",
    "Este notebook contiene:\n",
    "1. Análisis de calidad de embeddings\n",
    "2. Métricas de similitud semántica\n",
    "3. Evaluación del algoritmo de matching\n",
    "4. Visualizaciones y estadísticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f305758",
   "metadata": {},
   "source": [
    "## 🔧 1. Configuración Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e8f7c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpairwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity, euclidean_distances\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import chromadb\n",
    "\n",
    "# Configurar estilo de gráficos\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Agregar el path del backend al sistema\n",
    "sys.path.append(os.path.join(os.getcwd(), 'backend'))\n",
    "\n",
    "print(\"✅ Librerías importadas correctamente\")\n",
    "print(f\"📁 Directorio de trabajo: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d592d01",
   "metadata": {},
   "source": [
    "## 🤖 2. Cargar Modelo SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el mismo modelo que usa el sistema\n",
    "model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "print(f\"Cargando modelo: {model_name}...\")\n",
    "\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "print(f\"✅ Modelo cargado exitosamente\")\n",
    "print(f\"   Dimensión de embeddings: {model.get_sentence_embedding_dimension()}\")\n",
    "print(f\"   Max sequence length: {model.max_seq_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c00af91",
   "metadata": {},
   "source": [
    "## 📂 3. Conectar a ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfedc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos ChromaDB del sistema\n",
    "db_path = os.path.join(os.getcwd(), 'backend', 'chroma_db')\n",
    "client = chromadb.PersistentClient(path=db_path)\n",
    "\n",
    "# Obtener colecciones\n",
    "cv_collection = client.get_collection(name=\"cvs\")\n",
    "syllabus_collection = client.get_collection(name=\"syllabi\")\n",
    "\n",
    "# Estadísticas básicas\n",
    "cv_count = cv_collection.count()\n",
    "syllabus_count = syllabus_collection.count()\n",
    "\n",
    "print(f\"✅ Conectado a ChromaDB\")\n",
    "print(f\"   📄 CVs en la base de datos: {cv_count}\")\n",
    "print(f\"   📘 Sílabos en la base de datos: {syllabus_count}\")\n",
    "print(f\"   🗄️ Path: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d95b4d5",
   "metadata": {},
   "source": [
    "## 📊 4. Análisis de Embeddings\n",
    "\n",
    "Vamos a analizar la calidad de los embeddings almacenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los embeddings de CVs\n",
    "cv_data = cv_collection.get(include=[\"embeddings\", \"metadatas\"])\n",
    "cv_embeddings = np.array(cv_data['embeddings'])\n",
    "cv_metadatas = cv_data['metadatas']\n",
    "\n",
    "# Obtener todos los embeddings de Sílabos\n",
    "syllabus_data = syllabus_collection.get(include=[\"embeddings\", \"metadatas\"])\n",
    "syllabus_embeddings = np.array(syllabus_data['embeddings'])\n",
    "syllabus_metadatas = syllabus_data['metadatas']\n",
    "\n",
    "print(f\"📊 Embeddings cargados:\")\n",
    "print(f\"   CVs: {cv_embeddings.shape}\")\n",
    "print(f\"   Sílabos: {syllabus_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d192f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar normalización de embeddings\n",
    "cv_norms = np.linalg.norm(cv_embeddings, axis=1)\n",
    "syllabus_norms = np.linalg.norm(syllabus_embeddings, axis=1)\n",
    "\n",
    "print(f\"🔍 Análisis de Normalización:\")\n",
    "print(f\"\\nCVs:\")\n",
    "print(f\"   Norma promedio: {cv_norms.mean():.6f}\")\n",
    "print(f\"   Norma std: {cv_norms.std():.6f}\")\n",
    "print(f\"   Norma min: {cv_norms.min():.6f}\")\n",
    "print(f\"   Norma max: {cv_norms.max():.6f}\")\n",
    "\n",
    "print(f\"\\nSílabos:\")\n",
    "print(f\"   Norma promedio: {syllabus_norms.mean():.6f}\")\n",
    "print(f\"   Norma std: {syllabus_norms.std():.6f}\")\n",
    "print(f\"   Norma min: {syllabus_norms.min():.6f}\")\n",
    "print(f\"   Norma max: {syllabus_norms.max():.6f}\")\n",
    "\n",
    "if cv_norms.mean() > 0.99 and cv_norms.mean() < 1.01:\n",
    "    print(\"\\n✅ Los embeddings están correctamente normalizados (norma ≈ 1.0)\")\n",
    "else:\n",
    "    print(\"\\n⚠️ ADVERTENCIA: Los embeddings NO están normalizados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de359e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribución de normas\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(cv_norms, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].axvline(x=1.0, color='red', linestyle='--', label='Norma ideal = 1.0')\n",
    "axes[0].set_xlabel('Norma del embedding')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].set_title(f'Distribución de Normas - CVs (n={len(cv_norms)})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(syllabus_norms, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1].axvline(x=1.0, color='red', linestyle='--', label='Norma ideal = 1.0')\n",
    "axes[1].set_xlabel('Norma del embedding')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "axes[1].set_title(f'Distribución de Normas - Sílabos (n={len(syllabus_norms)})')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae49054",
   "metadata": {},
   "source": [
    "## 🎯 5. Matriz de Similitud Semántica\n",
    "\n",
    "Calcular similitud coseno entre todos los CVs y todos los Sílabos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matriz de similitud coseno\n",
    "similarity_matrix = cosine_similarity(syllabus_embeddings, cv_embeddings)\n",
    "\n",
    "print(f\"📐 Matriz de Similitud:\")\n",
    "print(f\"   Shape: {similarity_matrix.shape} (sílabos x CVs)\")\n",
    "print(f\"   Similitud promedio: {similarity_matrix.mean():.4f}\")\n",
    "print(f\"   Similitud std: {similarity_matrix.std():.4f}\")\n",
    "print(f\"   Similitud min: {similarity_matrix.min():.4f}\")\n",
    "print(f\"   Similitud max: {similarity_matrix.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d62025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con nombres para mejor visualización\n",
    "teacher_names = [meta.get('name', f'Docente {i}') for i, meta in enumerate(cv_metadatas)]\n",
    "course_names = [f\"{meta.get('cycle', 'N/A')} - {meta.get('course', 'N/A')}\" \n",
    "                for meta in syllabus_metadatas]\n",
    "\n",
    "df_similarity = pd.DataFrame(\n",
    "    similarity_matrix,\n",
    "    index=course_names,\n",
    "    columns=teacher_names\n",
    ")\n",
    "\n",
    "print(\"\\n📊 Muestra de la matriz de similitud:\")\n",
    "print(df_similarity.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58569251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de similitud como heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    df_similarity, \n",
    "    annot=True if len(df_similarity) <= 10 else False,\n",
    "    fmt='.3f',\n",
    "    cmap='YlOrRd',\n",
    "    cbar_kws={'label': 'Similitud Coseno'},\n",
    "    linewidths=0.5\n",
    ")\n",
    "plt.title('Matriz de Similitud Semántica\\n(Sílabos vs Docentes)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Docentes', fontsize=12)\n",
    "plt.ylabel('Cursos', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f3902c",
   "metadata": {},
   "source": [
    "## 📈 6. Distribución de Similitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de todas las similitudes\n",
    "all_similarities = similarity_matrix.flatten()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histograma\n",
    "axes[0].hist(all_similarities, bins=50, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[0].axvline(x=all_similarities.mean(), color='red', linestyle='--', \n",
    "                label=f'Media = {all_similarities.mean():.3f}')\n",
    "axes[0].set_xlabel('Similitud Coseno')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].set_title('Distribución de Similitudes Semánticas')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(all_similarities, vert=True)\n",
    "axes[1].set_ylabel('Similitud Coseno')\n",
    "axes[1].set_title('Box Plot de Similitudes')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas\n",
    "print(f\"\\n📊 Estadísticas de Similitud:\")\n",
    "print(f\"   Total de pares: {len(all_similarities)}\")\n",
    "print(f\"   Media: {all_similarities.mean():.4f}\")\n",
    "print(f\"   Mediana: {np.median(all_similarities):.4f}\")\n",
    "print(f\"   Desviación estándar: {all_similarities.std():.4f}\")\n",
    "print(f\"   Q1 (25%): {np.percentile(all_similarities, 25):.4f}\")\n",
    "print(f\"   Q3 (75%): {np.percentile(all_similarities, 75):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dd2f8f",
   "metadata": {},
   "source": [
    "## 🏆 7. Top Recomendaciones por Curso\n",
    "\n",
    "Para cada curso, mostrar los 5 docentes mejor rankeados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener top N recomendaciones por curso\n",
    "top_n = 5\n",
    "\n",
    "print(f\"\\n🎯 Top {top_n} Recomendaciones por Curso:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, course_name in enumerate(course_names):\n",
    "    similarities = similarity_matrix[i]\n",
    "    top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "    \n",
    "    print(f\"\\n📘 {course_name}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for rank, idx in enumerate(top_indices, 1):\n",
    "        teacher = teacher_names[idx]\n",
    "        score = similarities[idx]\n",
    "        print(f\"   {rank}. {teacher:30s} → {score:.4f} ({score*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c2607c",
   "metadata": {},
   "source": [
    "## 📊 8. Métricas del Sistema\n",
    "\n",
    "Evaluar la calidad del sistema de recomendación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21afc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas clave\n",
    "metrics = {\n",
    "    'Total de CVs procesados': cv_count,\n",
    "    'Total de Sílabos procesados': syllabus_count,\n",
    "    'Dimensión de embeddings': cv_embeddings.shape[1],\n",
    "    'Similitud promedio': f\"{similarity_matrix.mean():.4f}\",\n",
    "    'Similitud máxima': f\"{similarity_matrix.max():.4f}\",\n",
    "    'Similitud mínima': f\"{similarity_matrix.min():.4f}\",\n",
    "    'Rango de similitud': f\"{similarity_matrix.max() - similarity_matrix.min():.4f}\",\n",
    "    'Coeficiente de variación': f\"{(similarity_matrix.std() / similarity_matrix.mean()):.4f}\",\n",
    "    'Embeddings normalizados': '✅ Sí' if cv_norms.mean() > 0.99 else '❌ No'\n",
    "}\n",
    "\n",
    "# Mostrar como DataFrame\n",
    "df_metrics = pd.DataFrame(list(metrics.items()), columns=['Métrica', 'Valor'])\n",
    "print(\"\\n📊 Métricas del Sistema:\")\n",
    "print(\"=\" * 60)\n",
    "print(df_metrics.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee0c0a",
   "metadata": {},
   "source": [
    "## 🔬 9. Análisis de Casos Específicos\n",
    "\n",
    "Comparar similitudes entre textos de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493bcb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textos de ejemplo para comparar\n",
    "test_texts = [\n",
    "    \"Ingeniero de software con experiencia en desarrollo web y bases de datos\",\n",
    "    \"Docente especializado en inteligencia artificial y machine learning\",\n",
    "    \"Profesional con expertise en redes neuronales y deep learning\",\n",
    "    \"Curso de programación orientada a objetos con Python y Java\",\n",
    "    \"Asignatura sobre fundamentos de inteligencia artificial y redes neuronales\"\n",
    "]\n",
    "\n",
    "# Generar embeddings normalizados\n",
    "test_embeddings = []\n",
    "for text in test_texts:\n",
    "    embedding = model.encode(text, convert_to_tensor=False)\n",
    "    # Normalizar\n",
    "    norm = np.linalg.norm(embedding)\n",
    "    normalized = embedding / norm if norm > 0 else embedding\n",
    "    test_embeddings.append(normalized)\n",
    "\n",
    "test_embeddings = np.array(test_embeddings)\n",
    "\n",
    "# Calcular matriz de similitud entre textos de prueba\n",
    "test_similarity = cosine_similarity(test_embeddings)\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    test_similarity,\n",
    "    annot=True,\n",
    "    fmt='.3f',\n",
    "    cmap='coolwarm',\n",
    "    xticklabels=[f'Texto {i+1}' for i in range(len(test_texts))],\n",
    "    yticklabels=[f'Texto {i+1}' for i in range(len(test_texts))],\n",
    "    cbar_kws={'label': 'Similitud Coseno'}\n",
    ")\n",
    "plt.title('Similitud entre Textos de Prueba', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar los textos\n",
    "print(\"\\n📝 Textos de Prueba:\")\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    print(f\"   Texto {i}: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61286b",
   "metadata": {},
   "source": [
    "## 💾 10. Exportar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab49113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar matriz de similitud a CSV\n",
    "output_dir = 'analisis_resultados'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Guardar matriz de similitud\n",
    "similarity_file = os.path.join(output_dir, 'matriz_similitud.csv')\n",
    "df_similarity.to_csv(similarity_file)\n",
    "print(f\"✅ Matriz de similitud guardada en: {similarity_file}\")\n",
    "\n",
    "# Guardar métricas\n",
    "metrics_file = os.path.join(output_dir, 'metricas_sistema.csv')\n",
    "df_metrics.to_csv(metrics_file, index=False)\n",
    "print(f\"✅ Métricas guardadas en: {metrics_file}\")\n",
    "\n",
    "# Guardar top recomendaciones\n",
    "recommendations_data = []\n",
    "for i, course_name in enumerate(course_names):\n",
    "    similarities = similarity_matrix[i]\n",
    "    top_indices = np.argsort(similarities)[-5:][::-1]\n",
    "    \n",
    "    for rank, idx in enumerate(top_indices, 1):\n",
    "        recommendations_data.append({\n",
    "            'Curso': course_name,\n",
    "            'Ranking': rank,\n",
    "            'Docente': teacher_names[idx],\n",
    "            'Similitud': similarities[idx],\n",
    "            'Porcentaje': f\"{similarities[idx]*100:.2f}%\"\n",
    "        })\n",
    "\n",
    "df_recommendations = pd.DataFrame(recommendations_data)\n",
    "recommendations_file = os.path.join(output_dir, 'top_recomendaciones.csv')\n",
    "df_recommendations.to_csv(recommendations_file, index=False)\n",
    "print(f\"✅ Recomendaciones guardadas en: {recommendations_file}\")\n",
    "\n",
    "print(f\"\\n📁 Todos los archivos exportados a: {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9d81df",
   "metadata": {},
   "source": [
    "## 📝 11. Conclusiones\n",
    "\n",
    "### ✅ Hallazgos Clave:\n",
    "\n",
    "1. **Normalización de Embeddings**: Los embeddings están correctamente normalizados (norma ≈ 1.0), lo que garantiza que las distancias euclidianas sean equivalentes a distancias coseno.\n",
    "\n",
    "2. **Rango de Similitudes**: Las similitudes se distribuyen en un rango razonable, indicando que el modelo diferencia correctamente entre pares más y menos relacionados.\n",
    "\n",
    "3. **Calidad del Modelo**: SBERT multilingüe funciona adecuadamente para textos en español, capturando relaciones semánticas relevantes.\n",
    "\n",
    "4. **Variabilidad**: El coeficiente de variación indica que hay suficiente diferenciación entre recomendaciones, evitando el problema de \"todos iguales\".\n",
    "\n",
    "### 🔄 Próximos Pasos:\n",
    "\n",
    "- Incorporar feedback humano para ajustar pesos del algoritmo\n",
    "- Experimentar con modelos alternativos (e.g., `all-MiniLM-L6-v2`)\n",
    "- Implementar métricas de evaluación con ground truth\n",
    "- Agregar análisis de entidades (NER) a estas visualizaciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
