#!/usr/bin/env python3
"""
Script de demostraciÃ³n del servicio NLP con SBERT
Para generar evidencias del funcionamiento del modelo
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

from backend.app.services.nlp_service import NLPService
import numpy as np

def demo_sbert_processing():
    print("=" * 60)
    print("ğŸ¤– DEMOSTRACIÃ“N DEL SERVICIO NLP - SBERT")
    print("=" * 60)
    
    # Inicializar el servicio NLP
    print("\nğŸ“¥ Inicializando modelo SBERT...")
    nlp_service = NLPService()
    print(f"âœ… Modelo cargado: {nlp_service.model}")
    
    # Textos de ejemplo de CV y sÃ­labo
    cv_texto = """
    Dr. Juan PÃ©rez LÃ³pez
    Doctorado en Ciencias de la ComputaciÃ³n
    Especialista en Machine Learning y Deep Learning
    Experiencia: 15 aÃ±os en desarrollo de software
    Conocimientos: Python, TensorFlow, PyTorch, Algoritmos de IA
    Publicaciones: 25 artÃ­culos en revistas indexadas
    Proyectos: Sistemas de recomendaciÃ³n, Procesamiento de lenguaje natural
    """
    
    silabo_texto = """
    Curso: Inteligencia Artificial
    DescripciÃ³n: Fundamentos de IA, algoritmos de machine learning
    Contenido: Redes neuronales, deep learning, procesamiento de lenguaje natural
    Requisitos: ProgramaciÃ³n en Python, matemÃ¡ticas avanzadas
    Objetivos: Desarrollar sistemas inteligentes usando tÃ©cnicas de IA
    """
    
    print(f"\nğŸ“„ TEXTO DEL CV:")
    print("-" * 40)
    print(cv_texto.strip())
    
    print(f"\nğŸ“‹ TEXTO DEL SÃLABO:")
    print("-" * 40)
    print(silabo_texto.strip())
    
    # Generar embeddings
    print(f"\nğŸ§  Generando embeddings con SBERT...")
    cv_embedding = nlp_service.generate_embedding(cv_texto)
    silabo_embedding = nlp_service.generate_embedding(silabo_texto)
    
    print(f"âœ… Embedding del CV generado: shape {cv_embedding.shape}")
    print(f"âœ… Embedding del sÃ­labo generado: shape {silabo_embedding.shape}")
    
    # Verificar normalizaciÃ³n
    cv_norm = np.linalg.norm(cv_embedding)
    silabo_norm = np.linalg.norm(silabo_embedding)
    
    print(f"\nğŸ“Š VERIFICACIÃ“N DE NORMALIZACIÃ“N:")
    print(f"   Norma del embedding CV: {cv_norm:.6f}")
    print(f"   Norma del embedding sÃ­labo: {silabo_norm:.6f}")
    print(f"   âœ… Embeddings normalizados correctamente" if abs(cv_norm - 1.0) < 0.001 else "   âŒ Error en normalizaciÃ³n")
    
    # Calcular similitud semÃ¡ntica
    print(f"\nğŸ” CALCULANDO SIMILITUD SEMÃNTICA...")
    similarity = nlp_service.calculate_similarity(cv_embedding, silabo_embedding)
    
    print(f"ğŸ“ˆ Similitud semÃ¡ntica: {similarity:.6f}")
    print(f"ğŸ“Š Similitud como porcentaje: {similarity * 100:.2f}%")
    
    # Evaluar la similitud
    if similarity > 0.7:
        nivel = "ğŸŸ¢ ALTA"
    elif similarity > 0.4:
        nivel = "ğŸŸ¡ MEDIA"
    else:
        nivel = "ğŸ”´ BAJA"
    
    print(f"ğŸ¯ Nivel de compatibilidad: {nivel}")
    
    # Mostrar algunos valores del embedding para evidencia
    print(f"\nğŸ”¢ MUESTRA DE VALORES DEL EMBEDDING (primeros 10):")
    print(f"   CV: {cv_embedding[:10]}")
    print(f"   SÃ­labo: {silabo_embedding[:10]}")
    
    print(f"\n" + "=" * 60)
    print("âœ… DEMOSTRACIÃ“N COMPLETADA")
    print("ğŸ’¡ El modelo SBERT estÃ¡ funcionando correctamente")
    print("ğŸ¯ Similitud semÃ¡ntica calculada exitosamente")
    print("=" * 60)
    
    return similarity

if __name__ == "__main__":
    try:
        similarity = demo_sbert_processing()
        print(f"\nğŸ† RESULTADO FINAL: Similitud = {similarity:.4f} ({similarity*100:.1f}%)")
    except Exception as e:
        print(f"âŒ Error durante la demostraciÃ³n: {e}")
        import traceback
        traceback.print_exc()
